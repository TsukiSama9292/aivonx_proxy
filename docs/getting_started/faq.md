# Frequently Asked Questions

## General Questions

### What is Aivonx Proxy?

Aivonx Proxy is a reverse proxy and management platform for multiple Ollama model-serving nodes. It provides intelligent routing, load balancing, and high availability features through a REST API and web-based administration interface.

### What problem does it solve?

It solves the challenge of managing multiple Ollama instances by:
- Providing a unified API endpoint
- Automatically routing requests to healthy nodes
- Load balancing based on node availability and performance
- Supporting model-aware routing (requests are only sent to nodes that have the required model)

## API Documentation

### How do I view the API documentation?

After starting the application, access the interactive API documentation at:
- **Swagger UI**: `/swagger`
- **ReDoc**: `/redoc`

These are automatically generated by drf-spectacular and provide interactive request testing.

### What API endpoints are available?

Key endpoints include:
- `/api/proxy/nodes` - CRUD operations for nodes
- `/api/proxy/state` - View proxy manager state
- `/api/proxy/active-requests` - Monitor active requests per node
- `/api/proxy/pull` - Pull models to nodes
- `/api/generate` - Generate completions
- `/api/chat` - Chat completions
- `/api/tags` - List available models

## Node Management

### How do I add a new node?

**Via API:**
```bash
curl -X POST http://localhost:8000/api/proxy/nodes \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer YOUR_TOKEN" \
  -d '{
    "name": "node1",
    "address": "192.168.1.100",
    "port": 11434
  }'
```

**Via Web UI:**
1. Log in to the management interface
2. Navigate to the Nodes section
3. Click "Add Node" and fill in the details

The system automatically performs a health check on the new node.

### How does node selection work?

The proxy uses configurable strategies:
- **Least Active** (default): Routes to the node with fewest active requests
- **Lowest Latency**: Routes to the node with best response time

You can change the strategy via the `/api/proxy/config` endpoint.

### What happens if a node goes down?

The health check scheduler (runs every minute by default) automatically:
- Detects unhealthy nodes
- Moves them to standby pool
- Stops routing new requests to them
- Re-adds them when they recover

## Troubleshooting

### Where are the logs?

Logs are stored in:
- `logs/django.json` - General Django logs
- `logs/proxy.json` - Proxy-specific logs
- `logs/django_error.log` - Error logs

### How do I check if nodes are healthy?

Use the state endpoint:
```bash
curl http://localhost:8000/api/proxy/state
```

This returns active and standby pools, latencies, and active request counts.

### Streaming responses aren't working

Make sure you're using an ASGI server (uvicorn) rather than WSGI (gunicorn with sync workers). Streaming requires async support.

## Configuration

### Can I change the health check interval?

Yes, modify the APScheduler configuration in your Django settings or adjust the scheduler directly in the proxy app configuration.

### How do I secure the API?

The API uses:
- JWT authentication (via djangorestframework-simplejwt)
- Session authentication
- Token authentication

Ensure you set proper CORS and CSRF trusted origins in production.
